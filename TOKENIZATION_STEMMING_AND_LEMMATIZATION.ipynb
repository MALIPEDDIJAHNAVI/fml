{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkxn2URjFgUc2/Wzhs9Zm2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MALIPEDDIJAHNAVI/fml/blob/main/TOKENIZATION_STEMMING_AND_LEMMATIZATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing sentences"
      ],
      "metadata": {
        "id": "-7WnTDB80357"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " using split"
      ],
      "metadata": {
        "id": "pGM7yipc07Yf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ii0qthis_Ci",
        "outputId": "6f10aaaf-6b09-4138-df50-f2ee6d03a373"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A writer should never have the audacity to write about themselves unless they’re willing to separate every layer of protection between the author’s soul and their book', ' The words should come directly from the center of the gut, tearing through flesh and bone as they break free', ' Ugly and honest and bloody and a little bit terrifying, but completely exposed', '']\n"
          ]
        }
      ],
      "source": [
        "para = \"\"\"A writer should never have the audacity to write about themselves unless they’re willing to separate every layer of protection between the author’s soul and their book. The words should come directly from the center of the gut, tearing through flesh and bone as they break free. Ugly and honest and bloody and a little bit terrifying, but completely exposed.\"\"\"\n",
        "print(para.split('.'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "using regular expression"
      ],
      "metadata": {
        "id": "D59DiBlo09cQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re"
      ],
      "metadata": {
        "id": "Xaq9jr4OvK_X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines = re.compile('[.?!] ').split(para)\n",
        "print(lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKezf0eAueac",
        "outputId": "0303758f-11e2-4ef6-9b7c-5f8db284a5f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A writer should never have the audacity to write about themselves unless they’re willing to separate every layer of protection between the author’s soul and their book', 'The words should come directly from the center of the gut, tearing through flesh and bone as they break free', 'Ugly and honest and bloody and a little bit terrifying, but completely exposed.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "using nltk"
      ],
      "metadata": {
        "id": "L0MXuKis1CuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install --user -U nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1slfeZMvOVw",
        "outputId": "017bb672-2c74-4a47-9654-67759f158e84"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i22VFMtqvTWo",
        "outputId": "d4428e9d-4244-4a2f-c9fe-e17740614646"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sentences = sent_tokenize(para)\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ8cftr60oJh",
        "outputId": "b2630363-d3e9-4265-d610-7a63455d96d7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A writer should never have the audacity to write about themselves unless they’re willing to separate every layer of protection between the author’s soul and their book.', 'The words should come directly from the center of the gut, tearing through flesh and bone as they break free.', 'Ugly and honest and bloody and a little bit terrifying, but completely exposed.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing words"
      ],
      "metadata": {
        "id": "OCrLZaBU00f5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "using split"
      ],
      "metadata": {
        "id": "uThGYt1s1E6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(para.split(' '))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycsKwHFl0xVo",
        "outputId": "c9035d9f-a69f-4585-dda3-35a3c402ab90"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'writer', 'should', 'never', 'have', 'the', 'audacity', 'to', 'write', 'about', 'themselves', 'unless', 'they’re', 'willing', 'to', 'separate', 'every', 'layer', 'of', 'protection', 'between', 'the', 'author’s', 'soul', 'and', 'their', 'book.', 'The', 'words', 'should', 'come', 'directly', 'from', 'the', 'center', 'of', 'the', 'gut,', 'tearing', 'through', 'flesh', 'and', 'bone', 'as', 'they', 'break', 'free.', 'Ugly', 'and', 'honest', 'and', 'bloody', 'and', 'a', 'little', 'bit', 'terrifying,', 'but', 'completely', 'exposed.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using regular expression"
      ],
      "metadata": {
        "id": "vXMTr3fR1R-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = re.findall(\"[\\w']+\", para)  \n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdOozeoH1KVh",
        "outputId": "b770361c-faec-4841-e5d9-6be74a0b1800"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'writer', 'should', 'never', 'have', 'the', 'audacity', 'to', 'write', 'about', 'themselves', 'unless', 'they', 're', 'willing', 'to', 'separate', 'every', 'layer', 'of', 'protection', 'between', 'the', 'author', 's', 'soul', 'and', 'their', 'book', 'The', 'words', 'should', 'come', 'directly', 'from', 'the', 'center', 'of', 'the', 'gut', 'tearing', 'through', 'flesh', 'and', 'bone', 'as', 'they', 'break', 'free', 'Ugly', 'and', 'honest', 'and', 'bloody', 'and', 'a', 'little', 'bit', 'terrifying', 'but', 'completely', 'exposed']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using nltk"
      ],
      "metadata": {
        "id": "2ktUhWLv1Ulp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize \n",
        "tokens = word_tokenize(para)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7T8RdrO1Xx-",
        "outputId": "a50ca7ea-3931-439a-97d9-b5cb16966cc5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'writer', 'should', 'never', 'have', 'the', 'audacity', 'to', 'write', 'about', 'themselves', 'unless', 'they', '’', 're', 'willing', 'to', 'separate', 'every', 'layer', 'of', 'protection', 'between', 'the', 'author', '’', 's', 'soul', 'and', 'their', 'book', '.', 'The', 'words', 'should', 'come', 'directly', 'from', 'the', 'center', 'of', 'the', 'gut', ',', 'tearing', 'through', 'flesh', 'and', 'bone', 'as', 'they', 'break', 'free', '.', 'Ugly', 'and', 'honest', 'and', 'bloody', 'and', 'a', 'little', 'bit', 'terrifying', ',', 'but', 'completely', 'exposed', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEMMING "
      ],
      "metadata": {
        "id": "U7kgsgPS15qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "\n",
        "sentence=\"A writer should never have the audacity to write about themselves unless they’re willing to separate every layer of protection between the author’s soul and their book. The words should come directly from the center of the gut, tearing through flesh and bone as they break free. Ugly and honest and bloody and a little bit terrifying, but completely exposed.\"\n",
        "\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "def stemSentence(sentence):\n",
        "    token_words=word_tokenize(sentence)\n",
        "    print(token_words)\n",
        "    stem_sentence=[]\n",
        "    for word in token_words:\n",
        "        stem_sentence.append(porter.stem(word))\n",
        "        stem_sentence.append(\" \")\n",
        "    return \"\".join(stem_sentence)\n",
        "\n",
        "x=stemSentence(sentence)\n",
        "print(\"Sentence after stemming :\", x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1ZGGzlM5o27",
        "outputId": "6539db40-9f7d-4b23-bca6-416a127f2c86"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'writer', 'should', 'never', 'have', 'the', 'audacity', 'to', 'write', 'about', 'themselves', 'unless', 'they', '’', 're', 'willing', 'to', 'separate', 'every', 'layer', 'of', 'protection', 'between', 'the', 'author', '’', 's', 'soul', 'and', 'their', 'book', '.', 'The', 'words', 'should', 'come', 'directly', 'from', 'the', 'center', 'of', 'the', 'gut', ',', 'tearing', 'through', 'flesh', 'and', 'bone', 'as', 'they', 'break', 'free', '.', 'Ugly', 'and', 'honest', 'and', 'bloody', 'and', 'a', 'little', 'bit', 'terrifying', ',', 'but', 'completely', 'exposed', '.']\n",
            "Sentence after stemming : a writer should never have the audac to write about themselv unless they ’ re will to separ everi layer of protect between the author ’ s soul and their book . the word should come directli from the center of the gut , tear through flesh and bone as they break free . ugli and honest and bloodi and a littl bit terrifi , but complet expos . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LEMMATIZATION"
      ],
      "metadata": {
        "id": "j7UuZ_7x78RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQIk4X6d8Oak",
        "outputId": "02dfaeee-18ec-43d4-ec8e-8edf9d4c199d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "sentence=\"A writer should never have the audacity to write about themselves unless they’re willing to separate every layer of protection between the author’s soul and their book. The words should come directly from the center of the gut, tearing through flesh and bone as they break free. Ugly and honest and bloody and a little bit terrifying, but completely exposed.\"\n",
        "\n",
        "punctuations=\"?:!.,;\"\n",
        "token_words = nltk.word_tokenize(sentence)\n",
        "print(token_words)\n",
        "\n",
        "lemma_sentence=[]\n",
        "for word in token_words:\n",
        "  lemma_sentence.append(wordnet_lemmatizer.lemmatize(word))\n",
        "  lemma_sentence.append(\" \")\n",
        "\n",
        "print(\"lemmas of tokens: \", ''.join(lemma_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmEQ0kSM77zh",
        "outputId": "2d706878-d1a4-48ec-8cd1-1d60fd84855f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'writer', 'should', 'never', 'have', 'the', 'audacity', 'to', 'write', 'about', 'themselves', 'unless', 'they', '’', 're', 'willing', 'to', 'separate', 'every', 'layer', 'of', 'protection', 'between', 'the', 'author', '’', 's', 'soul', 'and', 'their', 'book', '.', 'The', 'words', 'should', 'come', 'directly', 'from', 'the', 'center', 'of', 'the', 'gut', ',', 'tearing', 'through', 'flesh', 'and', 'bone', 'as', 'they', 'break', 'free', '.', 'Ugly', 'and', 'honest', 'and', 'bloody', 'and', 'a', 'little', 'bit', 'terrifying', ',', 'but', 'completely', 'exposed', '.']\n",
            "lemmas of tokens:  A writer should never have the audacity to write about themselves unless they ’ re willing to separate every layer of protection between the author ’ s soul and their book . The word should come directly from the center of the gut , tearing through flesh and bone a they break free . Ugly and honest and bloody and a little bit terrifying , but completely exposed . \n"
          ]
        }
      ]
    }
  ]
}